{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-05-21 01:32:21--  https://app.roboflow.com/ds/ZmvjpqMEmw?key=KNBGE8GmPQ\n",
      "Resolving app.roboflow.com (app.roboflow.com)... 151.101.65.195, 151.101.1.195, 2620:0:890::100\n",
      "Connecting to app.roboflow.com (app.roboflow.com)|151.101.65.195|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://storage.googleapis.com/roboflow-platform-regional-exports/lJgFDi6mCEUOZpvQIhTpHcQIqfR2/Ruo8DirsP4aHbysrCTMb/6/yolov8.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=481589474394-compute%40developer.gserviceaccount.com%2F20240520%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240520T163221Z&X-Goog-Expires=900&X-Goog-SignedHeaders=host&X-Goog-Signature=25d9d7233bd729c782f495af69d8acb019e36e3d1005fd308988f55412f1da4eefa7b948e0d3479a3b796a525e9d28aa95a28e094bd8aafa177cf147bbd066610d3b7809b8e80a6e15409348485420c1e03bb8711becd7e570b71017e3eb81127453533921fa44865a89b87fa31a8338920f6d9b7e3c81539a1580d1b099bff6df027b33938b5bcca88139710169c151c110cc4c097ac67d8fa70e79dcad6da4f1d9292c35a69f3208dc015d9f7ec902e5ad310cf822f0f60a1ebd1bfa1305d7336d10eec6bca6dd5eca8e6ca7b4af3f245c14da42f0bf1b7a9ecaa4335de3ae11fb818a2aae8da117eecabd7203785a03a3099b587832cd3084728356de9e75 [following]\n",
      "--2024-05-21 01:32:21--  https://storage.googleapis.com/roboflow-platform-regional-exports/lJgFDi6mCEUOZpvQIhTpHcQIqfR2/Ruo8DirsP4aHbysrCTMb/6/yolov8.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=481589474394-compute%40developer.gserviceaccount.com%2F20240520%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240520T163221Z&X-Goog-Expires=900&X-Goog-SignedHeaders=host&X-Goog-Signature=25d9d7233bd729c782f495af69d8acb019e36e3d1005fd308988f55412f1da4eefa7b948e0d3479a3b796a525e9d28aa95a28e094bd8aafa177cf147bbd066610d3b7809b8e80a6e15409348485420c1e03bb8711becd7e570b71017e3eb81127453533921fa44865a89b87fa31a8338920f6d9b7e3c81539a1580d1b099bff6df027b33938b5bcca88139710169c151c110cc4c097ac67d8fa70e79dcad6da4f1d9292c35a69f3208dc015d9f7ec902e5ad310cf822f0f60a1ebd1bfa1305d7336d10eec6bca6dd5eca8e6ca7b4af3f245c14da42f0bf1b7a9ecaa4335de3ae11fb818a2aae8da117eecabd7203785a03a3099b587832cd3084728356de9e75\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.206.251, 142.250.206.219, 142.250.76.155, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.206.251|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 85888238 (82M) [application/zip]\n",
      "Saving to: ‘traffic_sign_Data2.zip’\n",
      "\n",
      "traffic_sign_Data2. 100%[===================>]  81.91M  24.1MB/s    in 4.6s    \n",
      "\n",
      "2024-05-21 01:32:26 (17.7 MB/s) - ‘traffic_sign_Data2.zip’ saved [85888238/85888238]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O traffic_sign_Data2.zip https://app.roboflow.com/ds/ZmvjpqMEmw?key=KNBGE8GmPQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('./traffic_sign_Data2.zip') as target_file:\n",
    "    target_file.extractall('/home/boo/datasets/traffic_sign_Data2/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': ['bus', 'crosswalk', 'left', 'right', 'straight'],\n",
       " 'nc': 5,\n",
       " 'test': '/home/boo/datasets/traffic_sign_Data2/test/images/',\n",
       " 'train': '/home/boo/datasets/traffic_sign_Data2/train/images/',\n",
       " 'val': '/home/boo/datasets/traffic_sign_Data2/valid/images/'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yaml\n",
    "data = {'train':'/home/boo/datasets/traffic_sign_Data2/train/images/',\n",
    "        'val':'/home/boo/datasets/traffic_sign_Data2/valid/images/',\n",
    "        'test':'/home/boo/datasets/traffic_sign_Data2/test/images/',\n",
    "        'names':['bus','crosswalk','left','right','straight'],\n",
    "        'nc': 5}\n",
    "with open('/home/boo/datasets/traffic_sign_Data2/traffic_sign_Data2.yaml','w') as f:\n",
    "    yaml.dump(data,f)\n",
    "with open('/home/boo/datasets/traffic_sign_Data2/traffic_sign_Data2.yaml','r') as f:\n",
    "    traffic_yaml = yaml.safe_load(f)\n",
    "    display(traffic_yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m This integration is tested and supported for ultralytics v8.0.238 and below.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m             Please report any issues to https://github.com/wandb/wandb/issues with the tag `yolov8`.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mboo0828\u001b[0m (\u001b[33mircv\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/boo/Desktop/wandb/run-20240521_013909-plzi2pl8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ircv/embedded/runs/plzi2pl8' target=\"_blank\">YOLOv8-traffic-2</a></strong> to <a href='https://wandb.ai/ircv/embedded' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ircv/embedded' target=\"_blank\">https://wandb.ai/ircv/embedded</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ircv/embedded/runs/plzi2pl8' target=\"_blank\">https://wandb.ai/ircv/embedded/runs/plzi2pl8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "detect\n",
      "Ultralytics YOLOv8.2.16 🚀 Python-3.11.5 torch-2.2.1 CUDA:0 (NVIDIA GeForce RTX 3060, 12044MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/home/boo/datasets/traffic_sign_Data2/traffic_sign_Data2.yaml, epochs=200, time=None, patience=30, batch=32, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=embedded, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=embedded/train3\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752287  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3011823 parameters, 3011807 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir embedded/train3', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/boo/datasets/traffic_sign_Data2/train/labels... 445 images, 30 backgrounds, 0 corrupt: 100%|██████████| 445/445 [00:03<00:00, 129.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/boo/datasets/traffic_sign_Data2/train/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/boo/datasets/traffic_sign_Data2/valid/labels... 84 images, 7 backgrounds, 0 corrupt: 100%|██████████| 84/84 [00:00<00:00, 130.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/boo/datasets/traffic_sign_Data2/valid/labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to embedded/train3/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 416 train, 416 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1membedded/train3\u001b[0m\n",
      "Starting training for 200 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/200       2.1G      1.096        4.1      1.038         85        416: 100%|██████████| 14/14 [00:12<00:00,  1.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         84        124    0.00214      0.217    0.00601    0.00192\n",
      "Ultralytics YOLOv8.2.16 🚀 Python-3.11.5 torch-2.2.1 CUDA:0 (NVIDIA GeForce RTX 3060, 12044MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75165f047cd45fea4c57b6b77c2e108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Image: /home/boo/datasets/traffic_sign_Data2/valid/images/20240517152341691582_jpg.rf.b8073975d6137332329679a504b9008c.jpg has no bounding boxes labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Image: /home/boo/datasets/traffic_sign_Data2/valid/images/20240517152330026916_jpg.rf.5a4129b675d6787df4c1c76e43dfd941.jpg has no bounding boxes labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Image: /home/boo/datasets/traffic_sign_Data2/valid/images/20240517152328692715_jpg.rf.fa5a6b649fbc1e0c5c929f51c26dc747.jpg has no bounding boxes labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Image: /home/boo/datasets/traffic_sign_Data2/valid/images/20240517152325693789_jpg.rf.280ac3ea956f8a677a8df23821398296.jpg has no bounding boxes labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Image: /home/boo/datasets/traffic_sign_Data2/valid/images/20240517152647915664_jpg.rf.7afd44c6ff12195d636ff479444cf5f5.jpg has no bounding boxes labels\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Image: /home/boo/datasets/traffic_sign_Data2/valid/images/20240517152607924759_jpg.rf.b4d409c68998d98eb7bcbc7ef88ccfa0.jpg has no bounding boxes labels\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339f9e57d4b04e7e911da023a7193f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Image: /home/boo/datasets/traffic_sign_Data2/valid/images/20240517152249700504_jpg.rf.42b8f086bb1f908c53e5ec679a82a75f.jpg has no bounding boxes labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/200      2.08G     0.8524      2.285     0.8956         83        416: 100%|██████████| 14/14 [00:01<00:00, 10.79it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 15.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         84        124    0.00757      0.947      0.237      0.165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc1ac6d47004dc6a557b17ef59be065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f19cadef1d4d8a9731df3f93512415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/200      2.07G     0.7816      1.445     0.8828         67        416: 100%|██████████| 14/14 [00:01<00:00, 10.91it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 12.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         84        124    0.00612      0.893      0.271      0.221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90406d92d8d54efb9a0315883c80a11f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72f7aee6b791457d9e5afa8682bf00be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/200      2.06G     0.7331      1.156      0.875         88        416: 100%|██████████| 14/14 [00:01<00:00, 11.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 15.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         84        124    0.00703      0.992      0.776       0.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a49c21f0ed24b9ab73577f7198de2fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912f250170a14212aa2dfa79418bb5fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/200      2.06G     0.6972      1.043     0.8696         67        416: 100%|██████████| 14/14 [00:01<00:00, 11.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 15.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         84        124    0.00722          1      0.878      0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff5197552004ac1ba40a3a9b9862ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf5134c5fd9f4e4a98d13813ae10b5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/200      2.06G     0.6645     0.8926     0.8499         80        416: 100%|██████████| 14/14 [00:01<00:00, 11.29it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00, 14.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         84        124          1       0.46      0.959      0.818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2450604c720d49338bcd8ff6893f6dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating Visualizations for batch-1/1:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/PIL/ImageFile.py:536\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     fh \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mfileno()\n\u001b[1;32m    537\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m add_wandb_callback(model, enable_model_checkpointing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Step 4: Train and Fine-Tune the Model\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedded\u001b[39m\u001b[38;5;124m\"\u001b[39m, data\u001b[38;5;241m=\u001b[39mdataset_name, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, imgsz\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m416\u001b[39m, batch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,fliplr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Step 5: Validate the Model\u001b[39;00m\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39mval()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/model.py:674\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py:199\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_train(world_size)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py:419\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mval \u001b[38;5;129;01mor\u001b[39;00m final_epoch \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper\u001b[38;5;241m.\u001b[39mpossible_stop \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop:\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate()\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_metrics(metrics\u001b[38;5;241m=\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_loss_items(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtloss), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetrics, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr})\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopper(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfitness) \u001b[38;5;129;01mor\u001b[39;00m final_epoch\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py:560\u001b[0m, in \u001b[0;36mBaseTrainer.validate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    555\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;124;03m    Runs validation on test set using self.validator.\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \n\u001b[1;32m    558\u001b[0m \u001b[38;5;124;03m    The returned dict is expected to contain \"fitness\" key.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidator(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    561\u001b[0m     fitness \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfitness\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# use loss as fitness measure if not found\u001b[39;00m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_fitness \u001b[38;5;241m<\u001b[39m fitness:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/validator.py:200\u001b[0m, in \u001b[0;36mBaseValidator.__call__\u001b[0;34m(self, trainer, model)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalize_metrics()\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_results()\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_callbacks(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_val_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m    202\u001b[0m     model\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/validator.py:268\u001b[0m, in \u001b[0;36mBaseValidator.run_callbacks\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Runs all callbacks associated with a specified event.\"\"\"\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mget(event, []):\n\u001b[0;32m--> 268\u001b[0m     callback(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/integration/ultralytics/callback.py:362\u001b[0m, in \u001b[0;36mWandBUltralyticsCallback.on_val_end\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_table \u001b[38;5;241m=\u001b[39m plot_segmentation_validation_results(\n\u001b[1;32m    354\u001b[0m         dataloader\u001b[38;5;241m=\u001b[39mdataloader,\n\u001b[1;32m    355\u001b[0m         class_label_map\u001b[38;5;241m=\u001b[39mclass_label_map,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    359\u001b[0m         max_validation_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_validation_batches,\n\u001b[1;32m    360\u001b[0m     )\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdetect\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_table \u001b[38;5;241m=\u001b[39m plot_detection_validation_results(\n\u001b[1;32m    363\u001b[0m         dataloader\u001b[38;5;241m=\u001b[39mdataloader,\n\u001b[1;32m    364\u001b[0m         class_label_map\u001b[38;5;241m=\u001b[39mclass_label_map,\n\u001b[1;32m    365\u001b[0m         model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[1;32m    366\u001b[0m         predictor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor,\n\u001b[1;32m    367\u001b[0m         table\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_table,\n\u001b[1;32m    368\u001b[0m         max_validation_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_validation_batches,\n\u001b[1;32m    369\u001b[0m     )\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassify\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_table \u001b[38;5;241m=\u001b[39m plot_classification_validation_results(\n\u001b[1;32m    372\u001b[0m         dataloader\u001b[38;5;241m=\u001b[39mdataloader,\n\u001b[1;32m    373\u001b[0m         model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         max_validation_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_validation_batches,\n\u001b[1;32m    377\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/integration/ultralytics/bbox_utils.py:173\u001b[0m, in \u001b[0;36mplot_detection_validation_results\u001b[0;34m(dataloader, class_label_map, model_name, predictor, table, max_validation_batches, epoch)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_idx, prediction_result \u001b[38;5;129;01min\u001b[39;00m progress_bar_result_iterable:\n\u001b[1;32m    172\u001b[0m     prediction_result \u001b[38;5;241m=\u001b[39m prediction_result\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 173\u001b[0m     _, prediction_box_data, mean_confidence_map \u001b[38;5;241m=\u001b[39m plot_bbox_predictions(\n\u001b[1;32m    174\u001b[0m         prediction_result, model_name\n\u001b[1;32m    175\u001b[0m     )\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m         ground_truth_data \u001b[38;5;241m=\u001b[39m get_ground_truth_bbox_annotations(\n\u001b[1;32m    178\u001b[0m             img_idx, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mim_file\u001b[39m\u001b[38;5;124m\"\u001b[39m][img_idx], batch, class_label_map\n\u001b[1;32m    179\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/integration/ultralytics/bbox_utils.py:138\u001b[0m, in \u001b[0;36mplot_bbox_predictions\u001b[0;34m(result, model_name, table)\u001b[0m\n\u001b[1;32m    136\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    137\u001b[0m boxes, mean_confidence_map \u001b[38;5;241m=\u001b[39m get_boxes(result)\n\u001b[0;32m--> 138\u001b[0m image \u001b[38;5;241m=\u001b[39m wandb\u001b[38;5;241m.\u001b[39mImage(result\u001b[38;5;241m.\u001b[39morig_img[:, :, ::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], boxes\u001b[38;5;241m=\u001b[39mboxes)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m table \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     table\u001b[38;5;241m.\u001b[39madd_data(\n\u001b[1;32m    141\u001b[0m         model_name,\n\u001b[1;32m    142\u001b[0m         image,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    145\u001b[0m         result\u001b[38;5;241m.\u001b[39mspeed,\n\u001b[1;32m    146\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/data_types/image.py:179\u001b[0m, in \u001b[0;36mImage.__init__\u001b[0;34m(self, data_or_path, mode, caption, grouping, classes, boxes, masks, file_type)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_from_path(data_or_path)\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_from_data(data_or_path, mode, file_type)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_initialization_meta(\n\u001b[1;32m    181\u001b[0m     grouping, caption, classes, boxes, masks, file_type\n\u001b[1;32m    182\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/wandb/sdk/data_types/image.py:336\u001b[0m, in \u001b[0;36mImage._initialize_from_data\u001b[0;34m(self, data, mode, file_type)\u001b[0m\n\u001b[1;32m    334\u001b[0m tmp_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(MEDIA_TMP\u001b[38;5;241m.\u001b[39mname, runid\u001b[38;5;241m.\u001b[39mgenerate_id() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_image\u001b[38;5;241m.\u001b[39msave(tmp_path, transparency\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_file(tmp_path, is_tmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/PIL/Image.py:2439\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2436\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2438\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2439\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n\u001b[1;32m   2440\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   2441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/PIL/PngImagePlugin.py:1402\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1398\u001b[0m     im \u001b[38;5;241m=\u001b[39m _write_multiple_frames(\n\u001b[1;32m   1399\u001b[0m         im, fp, chunk, rawmode, default_image, append_images\n\u001b[1;32m   1400\u001b[0m     )\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im:\n\u001b[0;32m-> 1402\u001b[0m     ImageFile\u001b[38;5;241m.\u001b[39m_save(im, _idat(fp, chunk), [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip\u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m+\u001b[39m im\u001b[38;5;241m.\u001b[39msize, \u001b[38;5;241m0\u001b[39m, rawmode)])\n\u001b[1;32m   1404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info:\n\u001b[1;32m   1405\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m info_chunk \u001b[38;5;129;01min\u001b[39;00m info\u001b[38;5;241m.\u001b[39mchunks:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/PIL/ImageFile.py:540\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    538\u001b[0m     _encode_tile(im, fp, tile, bufsize, fh)\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation) \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 540\u001b[0m     _encode_tile(im, fp, tile, bufsize, \u001b[38;5;28;01mNone\u001b[39;00m, exc)\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    542\u001b[0m     fp\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/PIL/ImageFile.py:559\u001b[0m, in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc:\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;66;03m# compress to Python file-compatible object\u001b[39;00m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 559\u001b[0m         errcode, data \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mencode(bufsize)[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    560\u001b[0m         fp\u001b[38;5;241m.\u001b[39mwrite(data)\n\u001b[1;32m    561\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from wandb.integration.ultralytics import add_wandb_callback\n",
    "import wandb\n",
    "import gc\n",
    "import torch \n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "wandb.init(project=\"embedded\", \n",
    "           name = \"YOLOv8-traffic-2\",\n",
    "           job_type=\"training\")\n",
    "\n",
    "model_name = \"yolov8n\"\n",
    "dataset_name = \"/home/boo/datasets/traffic_sign_Data2/traffic_sign_Data2.yaml\"\n",
    "model = YOLO(f\"{model_name}.pt\")\n",
    "\n",
    "add_wandb_callback(model, enable_model_checkpointing=True)\n",
    "\n",
    "model.train(project=\"embedded\", data=dataset_name, epochs=200, imgsz=416, batch=32,patience=30,fliplr=0)\n",
    "\n",
    "model.val()\n",
    "\n",
    "print(type(model.names),len(model.names))\n",
    "print(model.names)\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ TensorRT requires GPU export, automatically assigning device=0\n",
      "Ultralytics YOLOv8.2.16 🚀 Python-3.11.5 torch-2.2.1 CUDA:0 (NVIDIA GeForce RTX 3060, 12044MiB)\n",
      "WARNING ⚠️ INT8 export requires a missing 'data' arg for calibration. Using default 'data=coco8.yaml'.\n",
      "Model summary (fused): 168 layers, 3006623 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 9, 8400) (5.9 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnxsim>=0.4.33', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ❌ AutoUpdate skipped (offline)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m simplifier failure: No module named 'onnxsim'\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ✅ 0.8s, saved as 'best.onnx' (11.5 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['nvidia-tensorrt'] not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ❌ AutoUpdate skipped (offline)\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export failure ❌ 0.8s: No module named 'tensorrt'\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorrt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/exporter.py:677\u001b[0m, in \u001b[0;36mExporter.export_engine\u001b[0;34m(self, prefix)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 677\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorrt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtrt\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorrt'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Export the model to TensorRT format\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m model\u001b[38;5;241m.\u001b[39mexport(\u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m'\u001b[39m, imgsz\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m640\u001b[39m,\u001b[38;5;241m640\u001b[39m), half \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, int8 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, simplify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# creates 'yolov8n.engine'\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Load the exported TensorRT model\u001b[39;00m\n\u001b[1;32m     10\u001b[0m tensorrt_model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest.engine\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/model.py:602\u001b[0m, in \u001b[0;36mModel.export\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m custom \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgsz\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimgsz\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# method defaults\u001b[39;00m\n\u001b[1;32m    601\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverrides, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcustom, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexport\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# highest priority args on the right\u001b[39;00m\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Exporter(overrides\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/exporter.py:296\u001b[0m, in \u001b[0;36mExporter.__call__\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    294\u001b[0m     f[\u001b[38;5;241m0\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_torchscript()\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine:  \u001b[38;5;66;03m# TensorRT required before ONNX\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m     f[\u001b[38;5;241m1\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_engine()\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m onnx:  \u001b[38;5;66;03m# ONNX\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     f[\u001b[38;5;241m2\u001b[39m], _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexport_onnx()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/exporter.py:142\u001b[0m, in \u001b[0;36mtry_export.<locals>.outer_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    141\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m export failure ❌ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/exporter.py:137\u001b[0m, in \u001b[0;36mtry_export.<locals>.outer_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Profile() \u001b[38;5;28;01mas\u001b[39;00m dt:\n\u001b[0;32m--> 137\u001b[0m         f, model \u001b[38;5;241m=\u001b[39m inner_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m     LOGGER\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m export success ✅ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdt\u001b[38;5;241m.\u001b[39mt\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms, saved as \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_size(f)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f, model\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/exporter.py:681\u001b[0m, in \u001b[0;36mExporter.export_engine\u001b[0;34m(self, prefix)\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m LINUX:\n\u001b[1;32m    680\u001b[0m         check_requirements(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnvidia-tensorrt\u001b[39m\u001b[38;5;124m\"\u001b[39m, cmds\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-U --index-url https://pypi.ngc.nvidia.com\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 681\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorrt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtrt\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m    682\u001b[0m check_version(trt\u001b[38;5;241m.\u001b[39m__version__, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m7.0.0\u001b[39m\u001b[38;5;124m\"\u001b[39m, hard\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# require tensorrt>=7.0.0\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;66;03m# Setup and checks\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorrt'"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO('best2.pt')\n",
    "\n",
    "# Export the model to TensorRT format\n",
    "model.export(format='engine', imgsz=(640,640), half =True, int8 = True, simplify = True)  # creates 'yolov8n.engine'\n",
    "\n",
    "# Load the exported TensorRT model\n",
    "tensorrt_model = YOLO('best2.engine')\n",
    "\n",
    "# Run inference\n",
    "results1 = model('https://ultralytics.com/images/bus.jpg')\n",
    "results2 = tensorrt_model('https://ultralytics.com/images/bus.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
